{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_lengths = dict()\n",
    "with open('./lengths.title', 'rb') as fin:\n",
    "    title_lengths = pickle.load(fin)\n",
    "    \n",
    "text_lengths = dict()\n",
    "with open('./lengths.text', 'rb') as fin:\n",
    "    text_lengths = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_avgdl = np.mean(list(title_lengths.values()))\n",
    "text_avgdl = np.mean(list(text_lengths.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_title = dict()\n",
    "# df_text = dict()\n",
    "df_total = dict()\n",
    "\n",
    "# with open('./title.df', 'rb') as fin:\n",
    "#     df_title = pickle.load(fin)\n",
    "\n",
    "# with open('./text.df', 'rb') as fin:\n",
    "#     df_text = pickle.load(fin)\n",
    "\n",
    "with open('./total.df', 'rb') as fin:\n",
    "    df_total = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = Mystem()\n",
    "pattern = re.compile('\\d+|[^\\W\\d]+')\n",
    "stemmer = SnowballStemmer('russian', ignore_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = []\n",
    "with open('queries.final', 'r') as fin:\n",
    "    for line in fin:\n",
    "        q = line.split('\\t')[1]\n",
    "        queries.append(list(map(lambda x: stemmer.stem(lemmatizer.lemmatize(x)[0]), pattern.findall(q))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('./sample.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2docs = []\n",
    "for i in range(6311):\n",
    "    q2docs.append(list(sample[sample['QueryId'] == i]['DocumentId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 100\n",
      "processed 200\n",
      "processed 300\n",
      "processed 400\n",
      "processed 500\n",
      "processed 600\n",
      "processed 700\n",
      "processed 800\n",
      "processed 900\n",
      "processed 1000\n",
      "processed 1100\n",
      "processed 1200\n",
      "processed 1300\n",
      "processed 1400\n",
      "processed 1500\n",
      "processed 1600\n",
      "processed 1700\n",
      "processed 1800\n",
      "processed 1900\n",
      "processed 2000\n",
      "processed 2100\n",
      "processed 2200\n",
      "processed 2300\n",
      "processed 2400\n",
      "processed 2500\n",
      "processed 2600\n",
      "processed 2700\n",
      "processed 2800\n",
      "processed 2900\n",
      "processed 3000\n",
      "processed 3100\n",
      "processed 3200\n",
      "processed 3300\n",
      "processed 3400\n",
      "processed 3500\n",
      "processed 3600\n",
      "processed 3700\n",
      "processed 3800\n",
      "processed 3900\n",
      "processed 4000\n",
      "processed 4100\n",
      "processed 4200\n",
      "processed 4300\n",
      "processed 4400\n",
      "processed 4500\n",
      "processed 4600\n",
      "processed 4700\n",
      "processed 4800\n",
      "processed 4900\n",
      "processed 5000\n",
      "processed 5100\n",
      "processed 5200\n",
      "processed 5300\n",
      "processed 5400\n",
      "processed 5500\n",
      "processed 5600\n",
      "processed 5700\n",
      "processed 5800\n",
      "processed 5900\n",
      "processed 6000\n",
      "processed 6100\n",
      "processed 6200\n",
      "processed 6300\n"
     ]
    }
   ],
   "source": [
    "marks = []\n",
    "weights = [0.5, 1.0]\n",
    "N = 582167\n",
    "for q, i in zip(queries, range(len(queries))):\n",
    "    marks.append([])\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        print('processed', i + 1)\n",
    "    \n",
    "    for doc_id in q2docs[i]:\n",
    "        idx = str(doc_id)\n",
    "        \n",
    "        fq_title = dict()\n",
    "        fq_text = dict()\n",
    "        with open('./frequences/' + idx + '.title', 'rb') as fin:\n",
    "            fq_title = pickle.load(fin)\n",
    "        with open('./frequences/' + idx + '.text', 'rb') as fin:\n",
    "            fq_text = pickle.load(fin)\n",
    "        \n",
    "        rank = 0.0\n",
    "        for w in q:\n",
    "            if not w in df_total:\n",
    "                continue\n",
    "\n",
    "            if df_total[w] > N // 2:\n",
    "                continue\n",
    "                \n",
    "            coeff = np.log((N - df_total[w] + 0.5) / (df_total[w] + 0.5))\n",
    "            mult = 0.0\n",
    "            \n",
    "            if w in fq_title:\n",
    "                mult += weights[0] * fq_title[w] * 1.0 / title_lengths[idx]\n",
    "                \n",
    "            if w in fq_text:\n",
    "                mult += weights[1] * fq_text[w] * 1.0 / text_lengths[idx]\n",
    "            rank += coeff * mult\n",
    "            \n",
    "        marks[-1].append(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 100\n",
      "processed 200\n",
      "processed 300\n",
      "processed 400\n",
      "processed 500\n",
      "processed 600\n",
      "processed 700\n",
      "processed 800\n",
      "processed 900\n",
      "processed 1000\n",
      "processed 1100\n",
      "processed 1200\n",
      "processed 1300\n",
      "processed 1400\n",
      "processed 1500\n",
      "processed 1600\n",
      "processed 1700\n",
      "processed 1800\n",
      "processed 1900\n",
      "processed 2000\n",
      "processed 2100\n",
      "processed 2200\n",
      "processed 2300\n",
      "processed 2400\n",
      "processed 2500\n",
      "processed 2600\n",
      "processed 2700\n",
      "processed 2800\n",
      "processed 2900\n",
      "processed 3000\n",
      "processed 3100\n",
      "processed 3200\n",
      "processed 3300\n",
      "processed 3400\n",
      "processed 3500\n",
      "processed 3600\n",
      "processed 3700\n",
      "processed 3800\n",
      "processed 3900\n",
      "processed 4000\n",
      "processed 4100\n",
      "processed 4200\n",
      "processed 4300\n",
      "processed 4400\n",
      "processed 4500\n",
      "processed 4600\n",
      "processed 4700\n",
      "processed 4800\n",
      "processed 4900\n",
      "processed 5000\n",
      "processed 5100\n",
      "processed 5200\n",
      "processed 5300\n",
      "processed 5400\n",
      "processed 5500\n",
      "processed 5600\n",
      "processed 5700\n",
      "processed 5800\n",
      "processed 5900\n",
      "processed 6000\n",
      "processed 6100\n",
      "processed 6200\n",
      "processed 6300\n"
     ]
    }
   ],
   "source": [
    "marks = []\n",
    "weights = [3.0, 1.0]\n",
    "N = 582167\n",
    "k1 = 1.2\n",
    "b = 0.75\n",
    "\n",
    "for q, i in zip(queries, range(len(queries))):\n",
    "    marks.append([])\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        print('processed', i + 1)\n",
    "    \n",
    "    for doc_id in q2docs[i]:\n",
    "        idx = str(doc_id)\n",
    "        \n",
    "        fq_title = dict()\n",
    "        fq_text = dict()\n",
    "        with open('./frequences/' + idx + '.title', 'rb') as fin:\n",
    "            fq_title = pickle.load(fin)\n",
    "        with open('./frequences/' + idx + '.text', 'rb') as fin:\n",
    "            fq_text = pickle.load(fin)\n",
    "        \n",
    "        rank = 0.0\n",
    "        for w in q:\n",
    "            if not w in df_total:\n",
    "                continue\n",
    "\n",
    "            if df_total[w] > N // 2:\n",
    "                continue\n",
    "                \n",
    "            coeff = np.log((N - df_total[w] + 0.5) / (df_total[w] + 0.5))\n",
    "            mult = 0.0\n",
    "            \n",
    "            if w in fq_title:\n",
    "                mult += weights[0] * fq_title[w] * (k1 + 1.0) / (fq_title[w]+k1*(1-b+b*title_lengths[idx]/title_avgdl))\n",
    "                \n",
    "            if w in fq_text:\n",
    "                mult += weights[1] * fq_text[w] * (k1 + 1.0) / (fq_text[w]+k1*(1-b+b*text_lengths[idx]/text_avgdl))\n",
    "            rank += coeff * mult\n",
    "            \n",
    "        marks[-1].append(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for arr, i in zip(marks, range(6311)):\n",
    "    for idx in np.array(q2docs[i])[np.argsort(arr)[-1:-6:-1]]:\n",
    "        res.append([i, idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=['QueryId', 'DocumentId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['QueryId'] = res[:, 0]\n",
    "result['DocumentId'] = res[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./result.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryId</th>\n",
       "      <th>DocumentId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>49847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>563677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>461894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>64459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>53265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QueryId  DocumentId\n",
       "0        0       49847\n",
       "1        0      563677\n",
       "2        0      461894\n",
       "3        0       64459\n",
       "4        0       53265"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryId</th>\n",
       "      <th>DocumentId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>461894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>461895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>563677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>46868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>113720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QueryId  DocumentId\n",
       "0        0      461894\n",
       "1        0      461895\n",
       "2        0      563677\n",
       "3        0       46868\n",
       "4        0      113720"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/urllib3/connectionpool.py\", line 380, in _make_request\r\n",
      "    httplib_response = conn.getresponse(buffering=True)\r\n",
      "TypeError: getresponse() got an unexpected keyword argument 'buffering'\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/bin/kaggle\", line 9, in <module>\r\n",
      "    load_entry_point('kaggle==1.3.5', 'console_scripts', 'kaggle')()\r\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/kaggle/cli.py\", line 37, in main\r\n",
      "    out = args.func(**command_args)\r\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/kaggle/api/kaggle_api_extended.py\", line 196, in competition_submit\r\n",
      "    last_modified_date_utc=int(os.path.getmtime(file) * 1000)))\r\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/kaggle/api/kaggle_api.py\", line 773, in competitions_submissions_url_with_http_info\r\n",
      "    collection_formats=collection_formats)\r\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/kaggle/api_client.py\", line 334, in call_api\r\n",
      "    _preload_content, _request_timeout)\r\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/kaggle/api_client.py\", line 165, in __call_api\r\n",
      "    _request_timeout=_request_timeout)\r\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/kaggle/api_client.py\", line 377, in request\r\n",
      "    body=body)\r\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/kaggle/rest.py\", line 288, in POST\r\n",
      "    body=body)\r\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/kaggle/rest.py\", line 200, in request\r\n",
      "    headers=headers)\r\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/urllib3/request.py\", line 70, in request\r\n",
      "    **urlopen_kw)\r\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/urllib3/request.py\", line 148, in request_encode_body\r\n",
      "    return self.urlopen(method, url, **extra_kw)\r\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/urllib3/poolmanager.py\", line 321, in urlopen\r\n",
      "    response = conn.urlopen(method, u.request_uri, **kw)\r\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/urllib3/connectionpool.py\", line 601, in urlopen\r\n",
      "    chunked=chunked)\r\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/urllib3/connectionpool.py\", line 383, in _make_request\r\n",
      "    httplib_response = conn.getresponse()\r\n",
      "  File \"/usr/lib/python3.5/http/client.py\", line 1197, in getresponse\r\n",
      "    response.begin()\r\n",
      "  File \"/usr/lib/python3.5/http/client.py\", line 297, in begin\r\n",
      "    version, status, reason = self._read_status()\r\n",
      "  File \"/usr/lib/python3.5/http/client.py\", line 258, in _read_status\r\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\r\n",
      "  File \"/usr/lib/python3.5/socket.py\", line 575, in readinto\r\n",
      "    return self._sock.recv_into(b)\r\n",
      "  File \"/usr/lib/python3.5/ssl.py\", line 929, in recv_into\r\n",
      "    return self.read(nbytes, buffer)\r\n",
      "  File \"/usr/lib/python3.5/ssl.py\", line 791, in read\r\n",
      "    return self._sslobj.read(len, buffer)\r\n",
      "  File \"/usr/lib/python3.5/ssl.py\", line 575, in read\r\n",
      "    v = self._sslobj.read(len, buffer)\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c ranking-long-tail-queries-ts-spring-2018 -f result.csv -m 'bm25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
